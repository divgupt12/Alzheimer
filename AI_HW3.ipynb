{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EKSujjdWvs0S"
      },
      "outputs": [],
      "source": [
        "train_root = \"/content/drive/MyDrive/AI/Alzheimer/train\"\n",
        "test_root = \"/content/drive/MyDrive/AI/Alzheimer/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qk7NxSxGkIWP"
      },
      "outputs": [],
      "source": [
        "batch_size = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZPWi9LJ4kLfF"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nMB0zohjkYYV"
      },
      "outputs": [],
      "source": [
        "Generator = ImageDataGenerator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXmcIUZfkeEA",
        "outputId": "0dbd5381-73ee-4f47-8243-0ae734de5e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5281 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data = Generator.flow_from_directory(train_root,(150,150),batch_size = batch_size,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2_tjDtEk2f3",
        "outputId": "b01b3dff-0703-42d0-862b-e0dc99271c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1479 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "test_data = Generator.flow_from_directory(test_root,(150,150),batch_size = batch_size,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_t4D-N0LlIbh"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pCVSYyqXlWMF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import array_to_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Cmt1MiYZllMr"
      },
      "outputs": [],
      "source": [
        "img = array_to_img(train_data[0][0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "w4fF5CJJls7D"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Zk5izxX0ms0E"
      },
      "outputs": [],
      "source": [
        "num_class = len([i for i in os.listdir(train_root)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOJ4nKBzm7zB",
        "outputId": "9811f5f8-d3bb-4c04-d33b-e3caea4a8d6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "num_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-gqYwWmbnEmd"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "No6xVPTSnJy0"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mSLZ7ALxnYNP"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2jZ1xNzIngJQ"
      },
      "outputs": [],
      "source": [
        "model.add(Conv2D((32),(3,3),input_shape = (150,150,3),activation=\"relu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ibTDP81cn9ie"
      },
      "outputs": [],
      "source": [
        "model.add(MaxPool2D(pool_size=(2,2),strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JhmTdRwroMRi"
      },
      "outputs": [],
      "source": [
        "model.add(Dropout(0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "H8s4ghz8oUT8"
      },
      "outputs": [],
      "source": [
        "model.add(Conv2D((32),(3,3),activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=2))\n",
        "model.add(Dropout(0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZNQIoH8YoatC"
      },
      "outputs": [],
      "source": [
        "model.add(Conv2D((64),(3,3),activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=2))\n",
        "model.add(Dropout(0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "S-WtQ1P1od6L"
      },
      "outputs": [],
      "source": [
        "model.add(Conv2D((64),(3,3),activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=2))\n",
        "model.add(Dropout(0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NYJEmd_wofzy"
      },
      "outputs": [],
      "source": [
        "model.add(Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqalQB7conHL",
        "outputId": "68af1cd1-afee-444a-9cda-e86351a360ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 36, 36, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 17, 17, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3136)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,568\n",
            "Trainable params: 65,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sZee5XBeooLx"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(128,activation = \"relu\"))\n",
        "model.add(Dropout(0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kNy2q5t7o_A5"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(num_class, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KT0mkvQuqN9l"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer= \"adam\",metrics =[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO7No63oqjKM",
        "outputId": "00994fd7-7979-4194-f5ce-bd1561a85dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/72\n",
            "529/529 [==============================] - 1420s 3s/step - loss: 3.2558 - accuracy: 0.4482\n",
            "Epoch 2/72\n",
            "529/529 [==============================] - 166s 315ms/step - loss: 1.0650 - accuracy: 0.4806\n",
            "Epoch 3/72\n",
            "529/529 [==============================] - 167s 315ms/step - loss: 1.0491 - accuracy: 0.4823\n",
            "Epoch 4/72\n",
            "529/529 [==============================] - 169s 319ms/step - loss: 1.0450 - accuracy: 0.4789\n",
            "Epoch 5/72\n",
            "529/529 [==============================] - 169s 320ms/step - loss: 1.0494 - accuracy: 0.4893\n",
            "Epoch 6/72\n",
            "529/529 [==============================] - 167s 316ms/step - loss: 1.0492 - accuracy: 0.4876\n",
            "Epoch 7/72\n",
            "529/529 [==============================] - 166s 315ms/step - loss: 1.0167 - accuracy: 0.5062\n",
            "Epoch 8/72\n",
            "529/529 [==============================] - 166s 315ms/step - loss: 0.9993 - accuracy: 0.5094\n",
            "Epoch 9/72\n",
            "529/529 [==============================] - 168s 318ms/step - loss: 0.9832 - accuracy: 0.5249\n",
            "Epoch 10/72\n",
            "529/529 [==============================] - 167s 317ms/step - loss: 0.9998 - accuracy: 0.4978\n",
            "Epoch 11/72\n",
            "529/529 [==============================] - 167s 317ms/step - loss: 0.9737 - accuracy: 0.5230\n",
            "Epoch 12/72\n",
            "529/529 [==============================] - 167s 315ms/step - loss: 0.9812 - accuracy: 0.5266\n",
            "Epoch 13/72\n",
            "529/529 [==============================] - 166s 314ms/step - loss: 0.9625 - accuracy: 0.5471\n",
            "Epoch 14/72\n",
            "529/529 [==============================] - 164s 309ms/step - loss: 0.9452 - accuracy: 0.5249\n",
            "Epoch 15/72\n",
            "529/529 [==============================] - 163s 309ms/step - loss: 0.9258 - accuracy: 0.5525\n",
            "Epoch 16/72\n",
            "529/529 [==============================] - 163s 309ms/step - loss: 0.9495 - accuracy: 0.5588\n",
            "Epoch 17/72\n",
            "529/529 [==============================] - 165s 311ms/step - loss: 0.8829 - accuracy: 0.5652\n",
            "Epoch 18/72\n",
            "529/529 [==============================] - 163s 308ms/step - loss: 0.8578 - accuracy: 0.5810\n",
            "Epoch 19/72\n",
            "529/529 [==============================] - 162s 307ms/step - loss: 0.8593 - accuracy: 0.5730\n",
            "Epoch 20/72\n",
            "529/529 [==============================] - 163s 309ms/step - loss: 0.8434 - accuracy: 0.5965\n",
            "Epoch 21/72\n",
            "529/529 [==============================] - 164s 310ms/step - loss: 0.8310 - accuracy: 0.6048\n",
            "Epoch 22/72\n",
            "529/529 [==============================] - 161s 305ms/step - loss: 0.7926 - accuracy: 0.6236\n",
            "Epoch 23/72\n",
            "529/529 [==============================] - 162s 306ms/step - loss: 0.7833 - accuracy: 0.6256\n",
            "Epoch 24/72\n",
            "529/529 [==============================] - 161s 304ms/step - loss: 0.7701 - accuracy: 0.6431\n",
            "Epoch 25/72\n",
            "529/529 [==============================] - 161s 305ms/step - loss: 0.7533 - accuracy: 0.6504\n",
            "Epoch 26/72\n",
            "529/529 [==============================] - 165s 313ms/step - loss: 0.7248 - accuracy: 0.6635\n",
            "Epoch 27/72\n",
            "529/529 [==============================] - 164s 311ms/step - loss: 0.7236 - accuracy: 0.6699\n",
            "Epoch 28/72\n",
            "473/529 [=========================>....] - ETA: 17s - loss: 0.7219 - accuracy: 0.6759"
          ]
        }
      ],
      "source": [
        "h = model.fit(train_data, batch_size=5, epochs = 72)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPBEENO7CIq8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(h.history[\"accuracy\"])\n",
        "plt.title(\"Accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CW3QCs9nCJom"
      },
      "outputs": [],
      "source": [
        "plt.plot(h.history[\"loss\"])\n",
        "plt.title(\"Loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kpogoFrqwvz"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW1L7sjglNom"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gp6dL-dQlT8O"
      },
      "outputs": [],
      "source": [
        "predict_x=model.predict(test_data) \n",
        "pred=np.argmax(predict_x,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFl3VzT0lXkB"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(test_data.classes,pred)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVyBZLpflc-V"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsMJUo7ilhOO"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(cm, annot = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooKD6hP5mBHE"
      },
      "outputs": [],
      "source": [
        "print(\"accuracy is\", (cm[0,0]+cm[1,1]+cm[2,2],cm[3,3])/(sum(sum(cm))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Improving Results**\n",
        "\n",
        "As the data is quite complex, increasing the image size and batch size can improve the results significantly. The major challenge here is that due to complex nature of images, the model requires more data and time to accurately predict the images. \n",
        "\n",
        "**Pros and Cons of the model**\n",
        "\n",
        "Pro- Because Keras image processing networks have been in the arena for quite a long time, they have seen multiple category of unstrutured data and can perform better than the humans themselves. Keras uses the pattern of the given image to compare to those of the images it has already worked upon. This process thus makes the model more accurate in predicting the unstructured data.\n",
        "\n",
        "Cons - When dealing with unstructured data, this model requires a lot of data and time to continue to predict accurately. Because of this, the model tends to be very slow and the user loses the control over the categorisation of the images, making the process a black box. \n",
        "\n",
        "**Importance for the hospital**\n",
        "\n",
        "The hospital can use this model to predict the patients which are at a high risk of developing Alzeheimer. Since the model has 4 categories, appropriate treatments can be recommended on the basis of the severity of the disease in the patient. \n",
        "\n"
      ],
      "metadata": {
        "id": "sEY8hVBZJeg0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}